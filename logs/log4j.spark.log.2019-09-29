19/09/29 11:17:51 INFO SparkContext: Running Spark version 2.1.0
19/09/29 11:17:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/09/29 11:17:51 INFO SecurityManager: Changing view acls to: rstudio
19/09/29 11:17:51 INFO SecurityManager: Changing modify acls to: rstudio
19/09/29 11:17:51 INFO SecurityManager: Changing view acls groups to: 
19/09/29 11:17:51 INFO SecurityManager: Changing modify acls groups to: 
19/09/29 11:17:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(rstudio); groups with view permissions: Set(); users  with modify permissions: Set(rstudio); groups with modify permissions: Set()
19/09/29 11:17:52 INFO Utils: Successfully started service 'sparkDriver' on port 42759.
19/09/29 11:17:52 INFO SparkEnv: Registering MapOutputTracker
19/09/29 11:17:52 INFO SparkEnv: Registering BlockManagerMaster
19/09/29 11:17:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/09/29 11:17:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/09/29 11:17:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-45a2a9db-cf15-4560-841f-6e151fccf33f
19/09/29 11:17:52 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/09/29 11:17:52 INFO SparkEnv: Registering OutputCommitCoordinator
19/09/29 11:17:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/09/29 11:17:52 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/09/29 11:17:52 INFO SparkContext: Added JAR file:/home/rstudio/workspace/Rcourse/packrat/lib/x86_64-pc-linux-gnu/3.6.1/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:42759/jars/sparklyr-2.0-2.11.jar with timestamp 1569763072325
19/09/29 11:17:52 INFO Executor: Starting executor ID driver on host localhost
19/09/29 11:17:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43457.
19/09/29 11:17:52 INFO NettyBlockTransferService: Server created on 127.0.0.1:43457
19/09/29 11:17:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/09/29 11:17:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 43457, None)
19/09/29 11:17:52 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:43457 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 43457, None)
19/09/29 11:17:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 43457, None)
19/09/29 11:17:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 43457, None)
19/09/29 11:17:52 INFO SharedState: Warehouse path is 'file:/home/rstudio/workspace/Rcourse/spark-warehouse'.
19/09/29 11:17:52 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/09/29 11:17:53 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/09/29 11:17:53 INFO ObjectStore: ObjectStore, initialize called
19/09/29 11:17:53 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/09/29 11:17:53 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/09/29 11:17:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/09/29 11:17:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/09/29 11:17:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/09/29 11:17:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/09/29 11:17:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/09/29 11:17:55 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/09/29 11:17:55 INFO ObjectStore: Initialized ObjectStore
19/09/29 11:17:55 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/09/29 11:17:55 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/09/29 11:17:55 INFO HiveMetaStore: Added admin role in metastore
19/09/29 11:17:55 INFO HiveMetaStore: Added public role in metastore
19/09/29 11:17:55 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/09/29 11:17:56 INFO HiveMetaStore: 0: get_all_databases
19/09/29 11:17:56 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_all_databases	
19/09/29 11:17:56 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/09/29 11:17:56 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/09/29 11:17:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/09/29 11:17:56 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio
19/09/29 11:17:56 INFO SessionState: Created local directory: /tmp/rstudio
19/09/29 11:17:56 INFO SessionState: Created local directory: /tmp/58f3da18-f1dd-4ad8-b952-0ca8aee8cf70_resources
19/09/29 11:17:56 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio/58f3da18-f1dd-4ad8-b952-0ca8aee8cf70
19/09/29 11:17:56 INFO SessionState: Created local directory: /tmp/rstudio/58f3da18-f1dd-4ad8-b952-0ca8aee8cf70
19/09/29 11:17:56 INFO SessionState: Created HDFS directory: /tmp/hive/rstudio/58f3da18-f1dd-4ad8-b952-0ca8aee8cf70/_tmp_space.db
19/09/29 11:17:56 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/rstudio/workspace/Rcourse/spark-warehouse
19/09/29 11:17:56 INFO HiveMetaStore: 0: get_database: default
19/09/29 11:17:56 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 11:17:56 INFO HiveMetaStore: 0: get_database: global_temp
19/09/29 11:17:56 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/09/29 11:17:56 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/09/29 11:17:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/09/29 11:17:57 INFO HiveMetaStore: 0: get_database: default
19/09/29 11:17:57 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 11:17:57 INFO HiveMetaStore: 0: get_database: default
19/09/29 11:17:57 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 11:17:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/09/29 11:17:57 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/09/29 11:17:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/09/29 11:17:58 INFO HiveMetaStore: 0: get_database: default
19/09/29 11:17:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 11:17:58 INFO HiveMetaStore: 0: get_database: default
19/09/29 11:17:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 11:17:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/09/29 11:17:58 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/09/29 12:58:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/09/29 12:58:39 INFO HiveMetaStore: 0: get_database: default
19/09/29 12:58:39 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 12:58:39 INFO HiveMetaStore: 0: get_database: default
19/09/29 12:58:39 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 12:58:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/09/29 12:58:39 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/09/29 12:58:39 INFO CodeGenerator: Code generated in 286.370059 ms
19/09/29 12:58:39 INFO SparkContext: Starting job: collect at utils.scala:44
19/09/29 12:58:39 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/09/29 12:58:39 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/09/29 12:58:39 INFO DAGScheduler: Parents of final stage: List()
19/09/29 12:58:39 INFO DAGScheduler: Missing parents: List()
19/09/29 12:58:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:41), which has no missing parents
19/09/29 12:58:40 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 912.3 MB)
19/09/29 12:58:40 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 912.3 MB)
19/09/29 12:58:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:43457 (size: 4.6 KB, free: 912.3 MB)
19/09/29 12:58:40 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
19/09/29 12:58:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:41)
19/09/29 12:58:40 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/09/29 12:58:40 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
19/09/29 12:58:40 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/09/29 12:58:40 INFO Executor: Fetching spark://127.0.0.1:42759/jars/sparklyr-2.0-2.11.jar with timestamp 1569763072325
19/09/29 12:58:40 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:42759 after 9 ms (0 ms spent in bootstraps)
19/09/29 12:58:40 INFO Utils: Fetching spark://127.0.0.1:42759/jars/sparklyr-2.0-2.11.jar to /tmp/spark-58df9259-a262-43b6-98fd-6208c47309a3/userFiles-4af49c93-61cd-404e-93a7-e8d108f99ef1/fetchFileTemp5258189927858929013.tmp
19/09/29 12:58:40 INFO Executor: Adding file:/tmp/spark-58df9259-a262-43b6-98fd-6208c47309a3/userFiles-4af49c93-61cd-404e-93a7-e8d108f99ef1/sparklyr-2.0-2.11.jar to class loader
19/09/29 12:58:40 INFO CodeGenerator: Code generated in 12.437576 ms
19/09/29 12:58:40 INFO CodeGenerator: Code generated in 11.159222 ms
19/09/29 12:58:40 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
19/09/29 12:58:40 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 203 ms on localhost (executor driver) (1/1)
19/09/29 12:58:40 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/09/29 12:58:40 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.214 s
19/09/29 12:58:40 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.309190 s
19/09/29 12:58:46 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:43457 in memory (size: 4.6 KB, free: 912.3 MB)
19/09/29 12:58:47 INFO SparkSqlParser: Parsing command: flights
19/09/29 12:58:47 INFO SparkSqlParser: Parsing command: CACHE TABLE `flights`
19/09/29 12:58:47 INFO SparkSqlParser: Parsing command: `flights`
19/09/29 12:58:47 INFO CodeGenerator: Code generated in 16.032705 ms
19/09/29 12:58:47 INFO CodeGenerator: Code generated in 15.511173 ms
19/09/29 12:58:47 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/09/29 12:58:47 INFO DAGScheduler: Registering RDD 16 (sql at NativeMethodAccessorImpl.java:0)
19/09/29 12:58:47 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/09/29 12:58:47 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
19/09/29 12:58:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
19/09/29 12:58:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
19/09/29 12:58:47 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/09/29 12:58:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 30.7 KB, free 912.3 MB)
19/09/29 12:58:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.8 KB, free 912.3 MB)
19/09/29 12:58:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:43457 (size: 11.8 KB, free: 912.3 MB)
19/09/29 12:58:47 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
19/09/29 12:58:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
19/09/29 12:58:47 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/09/29 12:58:47 WARN TaskSetManager: Stage 1 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/09/29 12:58:47 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365403 bytes)
19/09/29 12:58:47 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/09/29 12:58:47 INFO ContextCleaner: Cleaned accumulator 1
19/09/29 12:58:47 INFO ContextCleaner: Cleaned accumulator 52
19/09/29 12:58:47 INFO ContextCleaner: Cleaned accumulator 0
19/09/29 12:58:48 INFO CodeGenerator: Code generated in 20.16491 ms
19/09/29 12:58:48 INFO CodeGenerator: Code generated in 94.5809 ms
19/09/29 12:58:51 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 22.5 MB, free 889.8 MB)
19/09/29 12:58:51 INFO BlockManagerInfo: Added rdd_13_0 in memory on 127.0.0.1:43457 (size: 22.5 MB, free: 889.8 MB)
19/09/29 12:58:51 INFO CodeGenerator: Code generated in 2.781677 ms
19/09/29 12:58:51 INFO CodeGenerator: Code generated in 12.288492 ms
19/09/29 12:58:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2820 bytes result sent to driver
19/09/29 12:58:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4185 ms on localhost (executor driver) (1/1)
19/09/29 12:58:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/09/29 12:58:51 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.187 s
19/09/29 12:58:51 INFO DAGScheduler: looking for newly runnable stages
19/09/29 12:58:51 INFO DAGScheduler: running: Set()
19/09/29 12:58:51 INFO DAGScheduler: waiting: Set(ResultStage 2)
19/09/29 12:58:51 INFO DAGScheduler: failed: Set()
19/09/29 12:58:51 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[19] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/09/29 12:58:51 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 889.8 MB)
19/09/29 12:58:51 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/09/29 12:58:51 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:43457 (size: 3.7 KB, free: 889.8 MB)
19/09/29 12:58:51 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
19/09/29 12:58:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[19] at sql at NativeMethodAccessorImpl.java:0)
19/09/29 12:58:51 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/09/29 12:58:51 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 5953 bytes)
19/09/29 12:58:51 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/09/29 12:58:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 12:58:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
19/09/29 12:58:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2129 bytes result sent to driver
19/09/29 12:58:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (executor driver) (1/1)
19/09/29 12:58:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/09/29 12:58:51 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.025 s
19/09/29 12:58:51 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.245664 s
19/09/29 12:58:51 INFO CodeGenerator: Code generated in 6.682297 ms
19/09/29 12:58:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `flights`
19/09/29 12:58:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/09/29 12:58:51 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:204)
19/09/29 12:58:51 INFO DAGScheduler: Got job 2 (collect at utils.scala:204) with 1 output partitions
19/09/29 12:58:51 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:204)
19/09/29 12:58:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/09/29 12:58:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/09/29 12:58:51 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:204), which has no missing parents
19/09/29 12:58:51 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 30.7 KB, free 889.7 MB)
19/09/29 12:58:51 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.7 KB, free 889.7 MB)
19/09/29 12:58:51 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:43457 (size: 11.7 KB, free: 889.8 MB)
19/09/29 12:58:51 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
19/09/29 12:58:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[23] at collect at utils.scala:204)
19/09/29 12:58:51 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/09/29 12:58:51 WARN TaskSetManager: Stage 3 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/09/29 12:58:51 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365395 bytes)
19/09/29 12:58:51 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/09/29 12:58:52 INFO BlockManager: Found block rdd_13_0 locally
19/09/29 12:58:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
19/09/29 12:58:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 349 ms on localhost (executor driver) (1/1)
19/09/29 12:58:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/09/29 12:58:52 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:204) finished in 0.350 s
19/09/29 12:58:52 INFO DAGScheduler: looking for newly runnable stages
19/09/29 12:58:52 INFO DAGScheduler: running: Set()
19/09/29 12:58:52 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/09/29 12:58:52 INFO DAGScheduler: failed: Set()
19/09/29 12:58:52 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:204), which has no missing parents
19/09/29 12:58:52 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 889.7 MB)
19/09/29 12:58:52 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 889.7 MB)
19/09/29 12:58:52 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:43457 (size: 3.7 KB, free: 889.8 MB)
19/09/29 12:58:52 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
19/09/29 12:58:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[26] at collect at utils.scala:204)
19/09/29 12:58:52 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/09/29 12:58:52 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 5945 bytes)
19/09/29 12:58:52 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/09/29 12:58:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 12:58:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/09/29 12:58:52 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
19/09/29 12:58:52 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
19/09/29 12:58:52 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/09/29 12:58:52 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:204) finished in 0.005 s
19/09/29 12:58:52 INFO DAGScheduler: Job 2 finished: collect at utils.scala:204, took 0.371461 s
19/09/29 12:58:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `flights` AS `zzz1`
WHERE (0 = 1)
19/09/29 12:58:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/09/29 12:58:52 INFO HiveMetaStore: 0: get_database: default
19/09/29 12:58:52 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 12:58:52 INFO HiveMetaStore: 0: get_database: default
19/09/29 12:58:52 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_database: default	
19/09/29 12:58:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/09/29 12:58:52 INFO audit: ugi=rstudio	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/09/29 12:58:52 INFO CodeGenerator: Code generated in 7.873294 ms
19/09/29 13:00:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `dbplyr_001`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/09/29 13:00:07 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:43457 in memory (size: 3.7 KB, free: 889.8 MB)
19/09/29 13:00:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:43457 in memory (size: 11.7 KB, free: 889.8 MB)
19/09/29 13:00:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:43457 in memory (size: 3.7 KB, free: 889.8 MB)
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 161
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 162
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 163
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 164
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 165
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 166
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 167
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 168
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 169
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 170
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 171
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 172
19/09/29 13:00:07 INFO ContextCleaner: Cleaned accumulator 173
19/09/29 13:00:07 INFO ContextCleaner: Cleaned shuffle 1
19/09/29 13:00:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `tailnum`, count(*) AS `count`, AVG(`distance`) AS `dist`, AVG(`arr_delay`) AS `delay`
FROM `flights`
GROUP BY `tailnum`) `dbplyr_002`
WHERE ((`count` > 20.0) AND (`dist` < 2000.0) AND (NOT(((`delay`) IS NULL))))
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 34.68006 ms
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 47.81447 ms
19/09/29 13:00:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/09/29 13:00:07 INFO DAGScheduler: Registering RDD 30 (collect at utils.scala:204)
19/09/29 13:00:07 INFO DAGScheduler: Got job 3 (collect at utils.scala:204) with 8 output partitions
19/09/29 13:00:07 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/09/29 13:00:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/09/29 13:00:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/09/29 13:00:07 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[30] at collect at utils.scala:204), which has no missing parents
19/09/29 13:00:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 50.3 KB, free 889.7 MB)
19/09/29 13:00:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.0 KB, free 889.7 MB)
19/09/29 13:00:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:43457 (size: 20.0 KB, free: 889.8 MB)
19/09/29 13:00:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
19/09/29 13:00:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[30] at collect at utils.scala:204)
19/09/29 13:00:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/09/29 13:00:07 WARN TaskSetManager: Stage 5 contains a task of very large size (27700 KB). The maximum recommended task size is 100 KB.
19/09/29 13:00:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 28365395 bytes)
19/09/29 13:00:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/09/29 13:00:07 INFO BlockManager: Found block rdd_13_0 locally
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 21.904415 ms
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 7.815628 ms
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 8.754669 ms
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 8.501802 ms
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 12.860984 ms
19/09/29 13:00:07 INFO CodeGenerator: Code generated in 6.89054 ms
19/09/29 13:00:08 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2373 bytes result sent to driver
19/09/29 13:00:08 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 754 ms on localhost (executor driver) (1/1)
19/09/29 13:00:08 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/09/29 13:00:08 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.755 s
19/09/29 13:00:08 INFO DAGScheduler: looking for newly runnable stages
19/09/29 13:00:08 INFO DAGScheduler: running: Set()
19/09/29 13:00:08 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/09/29 13:00:08 INFO DAGScheduler: failed: Set()
19/09/29 13:00:08 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/09/29 13:00:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 27.3 KB, free 889.7 MB)
19/09/29 13:00:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.7 KB, free 889.7 MB)
19/09/29 13:00:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:43457 (size: 11.7 KB, free: 889.8 MB)
19/09/29 13:00:08 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
19/09/29 13:00:08 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 6 (MapPartitionsRDD[33] at collect at utils.scala:204)
19/09/29 13:00:08 INFO TaskSchedulerImpl: Adding task set 6.0 with 8 tasks
19/09/29 13:00:08 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7, localhost, executor driver, partition 1, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 8, localhost, executor driver, partition 2, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 9, localhost, executor driver, partition 3, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 10, localhost, executor driver, partition 4, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 11, localhost, executor driver, partition 5, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 12, localhost, executor driver, partition 6, ANY, 5945 bytes)
19/09/29 13:00:08 INFO TaskSetManager: Starting task 7.0 in stage 6.0 (TID 13, localhost, executor driver, partition 7, ANY, 5945 bytes)
19/09/29 13:00:08 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/09/29 13:00:08 INFO Executor: Running task 1.0 in stage 6.0 (TID 7)
19/09/29 13:00:08 INFO Executor: Running task 2.0 in stage 6.0 (TID 8)
19/09/29 13:00:08 INFO Executor: Running task 3.0 in stage 6.0 (TID 9)
19/09/29 13:00:08 INFO Executor: Running task 4.0 in stage 6.0 (TID 10)
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO Executor: Running task 5.0 in stage 6.0 (TID 11)
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/09/29 13:00:08 INFO Executor: Running task 6.0 in stage 6.0 (TID 12)
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/09/29 13:00:08 INFO Executor: Running task 7.0 in stage 6.0 (TID 13)
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/09/29 13:00:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/09/29 13:00:08 INFO Executor: Finished task 2.0 in stage 6.0 (TID 8). 13737 bytes result sent to driver
19/09/29 13:00:08 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 8) in 34 ms on localhost (executor driver) (1/8)
19/09/29 13:00:08 INFO Executor: Finished task 5.0 in stage 6.0 (TID 11). 13105 bytes result sent to driver
19/09/29 13:00:08 INFO Executor: Finished task 3.0 in stage 6.0 (TID 9). 13066 bytes result sent to driver
19/09/29 13:00:08 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 11) in 36 ms on localhost (executor driver) (2/8)
19/09/29 13:00:08 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 9) in 37 ms on localhost (executor driver) (3/8)
19/09/29 13:00:08 INFO Executor: Finished task 4.0 in stage 6.0 (TID 10). 12550 bytes result sent to driver
19/09/29 13:00:08 INFO Executor: Finished task 1.0 in stage 6.0 (TID 7). 12309 bytes result sent to driver
19/09/29 13:00:08 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 10) in 38 ms on localhost (executor driver) (4/8)
19/09/29 13:00:08 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 40 ms on localhost (executor driver) (5/8)
19/09/29 13:00:08 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 12752 bytes result sent to driver
19/09/29 13:00:08 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 41 ms on localhost (executor driver) (6/8)
19/09/29 13:00:08 INFO Executor: Finished task 6.0 in stage 6.0 (TID 12). 12578 bytes result sent to driver
19/09/29 13:00:08 INFO Executor: Finished task 7.0 in stage 6.0 (TID 13). 11589 bytes result sent to driver
19/09/29 13:00:08 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 12) in 39 ms on localhost (executor driver) (7/8)
19/09/29 13:00:08 INFO TaskSetManager: Finished task 7.0 in stage 6.0 (TID 13) in 40 ms on localhost (executor driver) (8/8)
19/09/29 13:00:08 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/09/29 13:00:08 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.043 s
19/09/29 13:00:08 INFO DAGScheduler: Job 3 finished: collect at utils.scala:204, took 0.813228 s
19/09/29 13:00:08 INFO CodeGenerator: Code generated in 4.923756 ms
